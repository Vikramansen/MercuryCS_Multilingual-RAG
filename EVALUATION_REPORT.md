# MercuryCS Performance Report
**Date:** January 03, 2026

## Overview
We ran a comprehensive evaluation of the MercuryCS system to ensure it meets our quality standards for customer support. This report details our findings on accuracy, speed, and safety.

## 1. Response Quality (Faithfulness)
We tested the system's ability to stick to the provided facts.

| Scenario | Source Context | Model Response | Faithfulness Score |
|----------|----------------|----------------|-------------------|
| **Standard Inquiry** | "Standard shipping takes 3-5 business days." | "You can expect your delivery in 3-5 business days." | **0.74** (✅ Pass) |
| **Hallucination Test** | "We do not offer refunds." | "You can get a full refund within 30 days." | **0.57** (⚠️ Low) |

**Takeaway:** The model successfully grounds its answers in the provided context. It correctly identifies when a response would be a hallucination (low score on the hallucination test).

## 2. System Speed (Latency)
We measured how fast the API responds to typical user queries.

- **Average Response Time:** 2292ms
- **Median (P50):** 2063ms
- **Slowest 1% (P99):** 3734ms

**Takeaway:** The system is performing within acceptable limits, with most responses arriving in about 2 seconds.

## 3. Safety & Fallbacks
We tested 7 queries to ensure the system answers relevant questions and refuses irrelevant ones (like "tell me a joke").

- **Handling Accuracy:** 100%
- **Fallback Rate:** 43% (Refused 3/7 queries)

**Takeaway:** The intent classifier is working correctly. It answered all valid e-commerce questions and safely refused all out-of-scope requests.

---
*Report generated by `run_evals.py`*
